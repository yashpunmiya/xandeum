# Supabase Database Schema for XandScan

This document outlines the complete database schema needed for XandScan to work properly.

## Required Tables

### 1. `nodes` Table
Stores the registry of unique nodes (the "phonebook").

```sql
CREATE TABLE nodes (
  pubkey TEXT PRIMARY KEY,
  ip_address TEXT,
  gossip_port INT DEFAULT 9001,
  rpc_port INT DEFAULT 6000,
  country TEXT DEFAULT 'Unknown',
  city TEXT DEFAULT 'Unknown',
  latitude FLOAT,
  longitude FLOAT,
  isp TEXT,
  first_seen_at TIMESTAMPTZ DEFAULT NOW(),
  last_seen_at TIMESTAMPTZ DEFAULT NOW(),
  is_active BOOLEAN DEFAULT TRUE
);

-- Index for faster queries by IP address
CREATE INDEX idx_nodes_ip_address ON nodes(ip_address);

-- Index for active nodes
CREATE INDEX idx_nodes_is_active ON nodes(is_active);

-- Index for country filtering
CREATE INDEX idx_nodes_country ON nodes(country);
```

### 2. `snapshots` Table
Stores time-series data for graphs and historical tracking.

```sql
CREATE TABLE snapshots (
  id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  node_pubkey TEXT REFERENCES nodes(pubkey) ON DELETE CASCADE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  
  -- Metadata
  version TEXT,
  credits INT DEFAULT 0,
  
  -- Performance Stats (Nullable because RPC might fail)
  rpc_active BOOLEAN DEFAULT FALSE,
  cpu_percent FLOAT,
  ram_used BIGINT,
  ram_total BIGINT,
  uptime_seconds BIGINT,
  storage_used BIGINT,
  
  -- Calculated Score
  total_score FLOAT DEFAULT 0
);

-- Index for fast querying of history (MOST IMPORTANT)
CREATE INDEX idx_snapshots_pubkey_time ON snapshots(node_pubkey, created_at DESC);

-- Index for filtering by created_at for active window queries
CREATE INDEX idx_snapshots_created_at ON snapshots(created_at DESC);

-- Index for filtering by RPC active status
CREATE INDEX idx_snapshots_rpc_active ON snapshots(rpc_active);
```

## Key Features

### Scoring Algorithm
The `total_score` field is calculated based on:
- **Uptime (40%)**: `Math.min(100, uptime_seconds / 3600)`
- **Credits (30%)**: `Math.min(100, credits / 1000)`
- **Version (20%)**: 100 if matches network version, 50 otherwise
- **Resources (10%)**: `100 - cpu_percent`

### Network Support
The system supports both mainnet and devnet:
- **Devnet**: Data synced from `89.123.115.81:6000`
- **Mainnet**: Data synced from multiple entry nodes (161.97.97.41, etc.)

Network separation is achieved through time-based filtering:
- Only snapshots from the last 15 minutes are considered "active"
- When switching networks, the indexer creates new snapshots for that network
- Old snapshots remain for historical data

### Data Flow

1. **Cron Job** (`/api/cron/update-nodes?network=devnet|mainnet`)
   - Calls entry node RPC `get-pods-with-stats`
   - Fetches credits from external API
   - Enriches with geolocation data (cached in nodes table)
   - Calculates scores
   - Upserts nodes and inserts snapshots

2. **API Endpoints**
   - `/api/nodes?network=devnet|mainnet` - Returns nodes with latest snapshot stats
   - `/api/network-stats?network=devnet|mainnet` - Returns aggregated statistics
   - `/api/cron/update-nodes?network=devnet|mainnet` - Triggers data sync

3. **Dashboard**
   - Uses SWR for real-time data fetching
   - Network context provider for switching between mainnet/devnet
   - Live stats cards showing total nodes, active RPC, storage, top country
   - Interactive table with CPU, RAM, storage, uptime, credits, and score

## Environment Variables Required

```env
# Supabase
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key

# Cron Secret (for securing the update endpoint)
CRON_SECRET=your_secret_key

# Optional: Custom RPC endpoints
RPC_ENDPOINT_PRIMARY=http://161.97.97.41:6000/rpc
```

## Cron Setup

Set up two cron jobs for continuous data updates:

### Devnet Cron
```
URL: https://your-domain.vercel.app/api/cron/update-nodes?network=devnet
Method: GET
Headers: Authorization: Bearer YOUR_CRON_SECRET
Interval: Every 5-10 minutes
```

### Mainnet Cron
```
URL: https://your-domain.vercel.app/api/cron/update-nodes?network=mainnet
Method: GET
Headers: Authorization: Bearer YOUR_CRON_SECRET
Interval: Every 5-10 minutes
```

## Migration from MongoDB (if needed)

If you're migrating from MongoDB (like Xandash):

1. **nodes** collection → **nodes** table
   - Map `ip` → `ip_address`
   - Keep `pubkey`, `country`, `city`, `latitude`, `longitude`, `isp`

2. **node_snapshots** collection → **snapshots** table
   - Map fields accordingly
   - `timestamp` → `created_at`
   - `status` → `rpc_active` (online = true)

## Notes

- The scoring system prioritizes uptime and credits
- Geolocation is only fetched once per node (cached in nodes table)
- CPU/RAM data is optional and depends on RPC availability
- The 15-minute active window ensures fresh data while allowing historical tracking
- Indexes are critical for performance with large datasets

## Testing Queries

After setting up, test with:

```sql
-- Check total nodes
SELECT COUNT(*) FROM nodes;

-- Check recent snapshots
SELECT COUNT(*) FROM snapshots 
WHERE created_at > NOW() - INTERVAL '15 minutes';

-- Check top scoring nodes
SELECT n.pubkey, n.ip_address, s.total_score, s.credits, s.uptime_seconds
FROM nodes n
JOIN snapshots s ON n.pubkey = s.node_pubkey
WHERE s.created_at > NOW() - INTERVAL '15 minutes'
ORDER BY s.total_score DESC
LIMIT 10;

-- Check nodes with CPU/RAM data
SELECT COUNT(*) FROM snapshots 
WHERE created_at > NOW() - INTERVAL '15 minutes' 
AND cpu_percent IS NOT NULL;
```
